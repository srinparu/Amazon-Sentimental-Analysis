val df = sqlContext.read.json("s3://puchakaya/Input/metadata.json")
df.createOrReplaceTempView("amazon")
val df1=spark.sql("SELECT salesRank.Music,asin FROM AMAZON where salesRank.Music IS NOT NULL ORDER BY salesRank.Music")
df1.createOrReplaceTempView("music")
val df2 = sqlContext.read.json("s3://puchakaya/Input/item_dedup.json")
df2.createOrReplaceTempView("amazonReview")
val df3=sqlContext.sql("SELECT asin,COUNT(reviewText) AS CNT FROM amazonReview GROUP BY asin HAVING COUNT(reviewText)>200 ORDER BY CNT DESC" )
df3.createOrReplaceTempView("reviewTable")
val df4=sqlContext.sql("SELECT ar.asin,rt.CNT,ar.helpful,ar.overall,ar.reviewText,ar.reviewerID,ar.reviewerName,ar.summary,ar.unixReviewTime FROM amazonReview ar JOIN reviewTable rt ON rt.asin=ar.asin ORDER BY rt.CNT DESC" )
df4.createOrReplaceTempView("processedTable")
val df5=sqlContext.sql("SELECT pt.*,m.Music FROM processedTable pt JOIN music m ON m.asin=pt.asin ORDER BY m.Music")
df5.createOrReplaceTempView("finalTable")
val df6=sqlContext.sql("SELECT asin,CNT,helpful,overall,reviewText,reviewerID,reviewerName,summary,unixReviewTime,Music,COUNT(DISTINCT asin) AS C FROM finalTable GROUP BY asin,CNT,helpful,Music,overall,reviewText,reviewerID,reviewerName,summary,unixReviewTime ORDER BY C")
df6.show()
df6.write.mode("append").json("s3://puchakaya/Input/output.json")